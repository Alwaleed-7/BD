<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Big Data Exam Preparation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .sidebar-link {
            transition: all 0.2s ease-in-out;
        }
        .sidebar-link:hover, .sidebar-link.active {
            background-color: #4f46e5;
            color: white;
            transform: translateX(5px);
        }
        .quiz-option {
            transition: background-color 0.2s;
        }
        .quiz-option.selected {
            background-color: #6366f1;
            color: white;
            border-color: #4f46e5;
        }
        .prose {
            color: #374151;
        }
        .prose h2 {
            font-size: 1.75rem;
            font-weight: 700;
            margin-bottom: 1.5rem;
            margin-top: 2rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid #e5e7eb;
            color: #3730a3;
        }
        .prose h3 {
            font-size: 1.25rem;
            font-weight: 600;
            margin-top: 2rem;
            margin-bottom: 1rem;
            color: #4338ca;
        }
        .prose h4 {
            font-size: 1.1rem;
            font-weight: 600;
            margin-top: 1.5rem;
            margin-bottom: 0.75rem;
            color: #4f46e5;
        }
        .prose p, .prose li {
            color: #4b5563;
            line-height: 1.6;
        }
        .prose strong {
            color: #1f2937;
        }
        .prose ul, .prose ol {
            padding-left: 1.75rem;
            margin-bottom: 1rem;
        }
        .prose pre {
            background-color: #f3f4f6;
            padding: 1rem;
            border-radius: 0.5rem;
            white-space: pre-wrap;
            word-wrap: break-word;
            font-family: monospace;
            color: #111827;
            font-size: 0.9em;
        }
        .prose code {
            font-family: monospace;
            background-color: #e5e7eb;
            padding: 0.125rem 0.25rem;
            border-radius: 0.25rem;
            font-size: 0.9em;
        }
        .prose table {
            width: 100%;
            margin-top: 1.5em;
            margin-bottom: 1.5em;
            border-collapse: collapse;
        }
        .prose th, .prose td {
            border: 1px solid #d1d5db;
            padding: 0.75rem 1rem;
            text-align: left;
        }
        .prose th {
            background-color: #f3f4f6;
            font-weight: 600;
        }
        .answer-reveal {
            display: none;
            background-color: #f9fafb;
            border-left: 4px solid #6366f1;
            padding: 1rem;
            margin-top: 1rem;
            border-radius: 0.25rem;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <div class="flex h-screen">
        <!-- Sidebar -->
        <aside class="w-64 bg-gray-800 text-white p-6 fixed h-full shadow-lg overflow-y-auto">
            <h1 class="text-2xl font-bold mb-8 text-indigo-400">Big Data Prep</h1>
            <nav id="navigation">
                <!-- Navigation links will be inserted here by JavaScript -->
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="ml-64 flex-1 p-8 overflow-y-auto" id="main-content">
            <div id="content-area">
                <!-- Content will be dynamically loaded here -->
            </div>
        </main>
    </div>

    <script>
        const apiKey = "AIzaSyCQs0guVzFi67Bf5syQqQCPu9kJKo3g108"; 

        const appData = {
            chapters: [
                {
                    title: "Chapter 1: Intro to Big Data",
                    summary: `
                        <div class="prose max-w-none">
                        <h2>Introduction</h2>
                        <p>Big Data refers to a collection of data characterized by its massive volume, which grows exponentially over time. Its size and complexity exceed the capabilities of traditio[...] 
                         

                        <h2>The Characteristics of Big Data (The 5 Vs)</h2>
                        
                        <h3>Volume (Size)</h3>
                        <p>Refers to the massive size of data, ranging from terabytes (TB) to petabytes (PB), zettabytes (ZB), and beyond. The total amount of data created globally is projected to exc[...] 
                        <p><strong>Challenges:</strong> The immense size presents challenges for Storage (necessitating distributed file systems like HDFS), Access, and Processing (requiring distribut[...] 
                        
                        <h3>Variety (Complexity)</h3>
                        <p>Refers to the heterogeneity of data formats:</p>
                        <ol>
                            <li><strong>Structured Data:</strong> Highly organized data that fits into fixed schemas (e.g., Relational Database tables).</li>
                            <li><strong>Semi-Structured Data:</strong> Does not conform to a rigid structure but contains tags or markers to separate data elements (e.g., XML, JSON, log files).</li>
                            <li><strong>Unstructured Data:</strong> Lacks a predefined format, making it challenging to analyze with traditional methods (e.g., emails, videos, images, free-form text)[...] 
                        </ol>

                        <h3>Velocity (Speed)</h3>
                        <p>Refers to the increasing speed at which data is generated and the speed at which it needs to be processed.</p>
                        <ul>
                            <li><strong>Real-Time Processing:</strong> Instantly captures streaming data and processes it immediately to enable quick actions (e.g., fraud detection, live healthcare mo[...] 
                            <li><strong>Batch Processing:</strong> Data is collected, cleaned, and processed later in chunks, which is slower and can lead to missed opportunities for time-sensitive de[...] 
                        </ul>

                        <h3>Veracity (Quality)</h3>
                        <p>Refers to the quality, accuracy, reliability, and trustworthiness of the data. Big Data is often noisy, inconsistent, and uncertain.</p>
                        <p><strong>Uncertainty Sources:</strong> Unstructured nature of social media, high velocity leaving little time for traditional ETL (Extract, Transform, Load) quality checks, a[...] 
                        <p><strong>Example:</strong> The Google Flu Trends overestimation in 2013 demonstrated the danger of relying solely on uncertain big data without proper context and quality ass[...] 
                        
                        <h3>Value (Insight)</h3>
                        <p>The ultimate goal of processing Big Data is to extract meaningful insights that support data-driven decision-making. Without analysis, the data has little to no commercial v[...] 
                        
                       
                        </div>
                    `,
                    quiz: {
                        mcq: [
                            { q: "Which of the 3Vs refers to the different formats of data like structured, unstructured, and semi-structured?", options: ["Volume", "Velocity", "Variety", "Value"], a:[...] 
                            { q: "Data stored in a relational database table is an example of which type of data?", options: ["Unstructured", "Semi-structured", "Structured", "Complex"], a: "Structure[...] 
                            { q: "Which term describes the quality and trustworthiness of data?", options: ["Volume", "Veracity", "Velocity", "Value"], a: "Veracity" },
                            { q: "Real-time fraud detection is an application that primarily deals with which characteristic of Big Data?", options: ["Volume", "Variety", "Veracity", "Velocity"], a: "[...] 
                            { q: "What is the primary challenge associated with the 'Volume' of Big Data?", options: ["Data complexity", "Data speed", "Storage and processing", "Data quality"], a: "St[...] 
                        ],
                        fillIn: [
                            { q: "The process of tracking the origin and transformation of data is known as ________.", a: "Data Provenance" },
                            { q: "XML and JSON files are examples of ________ data.", a: "Semi-structured" },
                            { q: "Processing data in large chunks at a later time is called ________ processing.", a: "Batch" },
                            { q: "The ultimate goal of analyzing Big Data is to extract meaningful ________.", a: "Value" },
                            { q: "The 'V' that refers to the massive size of data is ________.", a: "Volume" }
                        ]
                    }
                },
                {
                    title: "Chapter 2: Storage Concepts",
                    summary: `
                        <div class="prose max-w-none">
                        <h2>Big Data Storage Architecture</h2>
                        <p>Traditional storage systems, particularly Relational Database Management Systems (RDBMS), are inadequate for handling the Volume, Velocity, and Variety of Big Data. New arch[...] 
                        <p>The typical architecture involves:</p>
                        <ol>
                            <li>Raw data (Machine, Web, Audio/Video, External) is ingested into a Hadoop Cluster (acting as a Data Lake).</li>
                            <li>The data is processed and refined.</li>
                            <li>Cleaned data is moved into a Data Warehouse (optimized for querying and reporting).</li>
                            <li>Users run ad-hoc queries against the Data Warehouse for insights.</li>
                        </ol>

                        <h2>Cluster Computing</h2>
                        <p>A cluster is a distributed system where multiple stand-alone computers, connected via a Local Area Network (LAN), work together as a single, highly available virtual machine[...] 
                        
                        <h3>Cluster Benefits</h3>
                        <p>The use of clusters provides critical benefits for Big Data systems:</p>
                        <ul>
                            <li><strong>Scalability:</strong> Nodes can be added or removed without disrupting operations.</li>
                            <li><strong>High Availability:</strong> If one node fails, others continue the work.</li>
                            <li><strong>Fault Tolerance:</strong> Automatic failover mechanisms transfer work from a failed node to a healthy one (no human intervention needed).</li>
                            <li><strong>Cost-Effective:</strong> Utilizes commodity hardware instead of expensive supercomputers.</li>
                        </ul>

                        <h3>Types and Structure of Clusters</h3>
                        <ol>
                            <li><strong>High Availability Clusters:</strong> Designed to minimize downtime. Nodes require access to shared storage, enabling a failed node's service to automatically fa[...] 
                            <li><strong>Load Balancing Clusters:</strong> Designed to share the computational workload among nodes to optimize performance, maximize throughput, and prevent any single [...] 
                        </ol>

                        
                        <h4>Cluster Structure (Symmetry)</h4>
                        <ul>
                            <li><strong>Symmetric Clusters (Active-Active):</strong> All nodes are active, run applications, and share the workload. No node is purely passive.</li>
                            <li><strong>Asymmetric Clusters (Active-Passive):</strong> Some nodes are active, while others are designated as "hot standby" (passive) and only take over if an active nod[...] 
                        </ul>

                        <h2>Data Distribution Models</h2>
                        <p>To handle massive datasets across clusters, data must be distributed efficiently.</p>
                        
                        <h3>Replication</h3>
                        <p>Replication is placing the same set of data (a replica or copy) across multiple nodes.
                        <strong>Advantages:</strong> Provides fault tolerance (data is not lost when a node crashes) and increases data availability.</p>
                        <ul>
                            <li><strong>Master-Slave Model:</strong> Writes occur only on the Master node and are replicated to Slave nodes. Reads are handled by the Slaves. This is efficient for inte[...] 
                            { Truncated for brevity } 
                        `
                }
            ]
        };
    </script>
</body>
</html>